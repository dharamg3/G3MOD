 Documentation/ABI/testing/sysfs-block-zram |   99 ++++
 drivers/staging/zram/Kconfig               |   12 -
 drivers/staging/zram/Makefile              |    2 +-
 drivers/staging/zram/xvmalloc.c            |   22 +-
 drivers/staging/zram/zram.txt              |   58 ++-
 drivers/staging/zram/zram_drv.c            |  670 ++++++++++++++--------------
 drivers/staging/zram/zram_drv.h            |  138 ++----
 drivers/staging/zram/zram_ioctl.h          |   41 --
 drivers/staging/zram/zram_sysfs.c          |  253 +++++++++++
 9 files changed, 760 insertions(+), 535 deletions(-)

diff --git a/Documentation/ABI/testing/sysfs-block-zram b/Documentation/ABI/testing/sysfs-block-zram
new file mode 100644
index 0000000..c8b3b48
--- /dev/null
+++ b/Documentation/ABI/testing/sysfs-block-zram
@@ -0,0 +1,99 @@
+What:		/sys/block/zram<id>/disksize
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The disksize file is read-write and specifies the disk size
+		which represents the limit on the *uncompressed* worth of data
+		that can be stored in this disk.
+
+What:		/sys/block/zram<id>/initstate
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The disksize file is read-only and shows the initialization
+		state of the device.
+
+What:		/sys/block/zram<id>/reset
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The disksize file is write-only and allows resetting the
+		device. The reset operation frees all the memory assocaited
+		with this device.
+
+What:		/sys/block/zram<id>/num_reads
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The num_reads file is read-only and specifies the number of
+		reads (failed or successful) done on this device.
+
+What:		/sys/block/zram<id>/num_writes
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The num_writes file is read-only and specifies the number of
+		writes (failed or successful) done on this device.
+
+What:		/sys/block/zram<id>/invalid_io
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The invalid_io file is read-only and specifies the number of
+		non-page-size-aligned I/O requests issued to this device.
+
+What:		/sys/block/zram<id>/notify_free
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The notify_free file is read-only and specifies the number of
+		swap slot free notifications received by this device. These
+		notifications are send to a swap block device when a swap slot
+		is freed. This statistic is applicable only when this disk is
+		being used as a swap disk.
+
+What:		/sys/block/zram<id>/discard
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The discard file is read-only and specifies the number of
+		discard requests received by this device. These requests
+		provide information to block device regarding blocks which are
+		no longer used by filesystem.
+
+What:		/sys/block/zram<id>/zero_pages
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The zero_pages file is read-only and specifies number of zero
+		filled pages written to this disk. No memory is allocated for
+		such pages.
+
+What:		/sys/block/zram<id>/orig_data_size
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The orig_data_size file is read-only and specifies uncompressed
+		size of data stored in this disk. This excludes zero-filled
+		pages (zero_pages) since no memory is allocated for them.
+		Unit: bytes
+
+What:		/sys/block/zram<id>/compr_data_size
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The compr_data_size file is read-only and specifies compressed
+		size of data stored in this disk. So, compression ratio can be
+		calculated using orig_data_size and this statistic.
+		Unit: bytes
+
+What:		/sys/block/zram<id>/mem_used_total
+Date:		August 2010
+Contact:	Nitin Gupta <ngupta@vflare.org>
+Description:
+		The mem_used_total file is read-only and specifies the amount
+		of memory, including allocator fragmentation and metadata
+		overhead, allocated for this disk. So, allocator space
+		efficiency can be calculated using compr_data_size and this
+		statistic.
+		Unit: bytes
\ No newline at end of file
diff --git a/drivers/staging/zram/Kconfig b/drivers/staging/zram/Kconfig
index 4654ae2..da079f8 100644
--- a/drivers/staging/zram/Kconfig
+++ b/drivers/staging/zram/Kconfig
@@ -15,15 +15,3 @@ config ZRAM
 
 	  See zram.txt for more information.
 	  Project home: http://compcache.googlecode.com/
-
-config ZRAM_STATS
-	bool "Enable statistics for compressed RAM disks"
-	depends on ZRAM
-	default y
-	help
-	  Enable statistics collection for compressed RAM devices. Statistics
-	  are exported through ioctl interface, so you have to use zramconfig
-	  program to get them. This adds only a minimal overhead.
-
-	  If unsure, say Y.
-
diff --git a/drivers/staging/zram/Makefile b/drivers/staging/zram/Makefile
index b2c087a..c01160a 100644
--- a/drivers/staging/zram/Makefile
+++ b/drivers/staging/zram/Makefile
@@ -1,3 +1,3 @@
-zram-objs	:=	zram_drv.o xvmalloc.o
+zram-objs	:=	zram_drv.o zram_sysfs.o xvmalloc.o
 
 obj-$(CONFIG_ZRAM)	+=	zram.o
diff --git a/drivers/staging/zram/xvmalloc.c b/drivers/staging/zram/xvmalloc.c
index 3fdbb8a..6268f65 100644
--- a/drivers/staging/zram/xvmalloc.c
+++ b/drivers/staging/zram/xvmalloc.c
@@ -20,16 +20,6 @@
 #include "xvmalloc.h"
 #include "xvmalloc_int.h"
 
-static void stat_inc(u64 *value)
-{
-	*value = *value + 1;
-}
-
-static void stat_dec(u64 *value)
-{
-	*value = *value - 1;
-}
-
 static int test_flag(struct block_header *block, enum blockflags flag)
 {
 	return block->prev & BIT(flag);
@@ -187,7 +177,7 @@ static void insert_block(struct xv_pool *pool, struct page *page, u32 offset,
 	slindex = get_index_for_insert(block->size);
 	flindex = slindex / BITS_PER_LONG;
 
-	block->link.prev_page = 0;
+	block->link.prev_page = NULL;
 	block->link.prev_offset = 0;
 	block->link.next_page = pool->freelist[slindex].page;
 	block->link.next_offset = pool->freelist[slindex].offset;
@@ -217,7 +207,7 @@ static void remove_block_head(struct xv_pool *pool,
 
 	pool->freelist[slindex].page = block->link.next_page;
 	pool->freelist[slindex].offset = block->link.next_offset;
-	block->link.prev_page = 0;
+	block->link.prev_page = NULL;
 	block->link.prev_offset = 0;
 
 	if (!pool->freelist[slindex].page) {
@@ -232,7 +222,7 @@ static void remove_block_head(struct xv_pool *pool,
 		 */
 		tmpblock = get_ptr_atomic(pool->freelist[slindex].page,
 				pool->freelist[slindex].offset, KM_USER1);
-		tmpblock->link.prev_page = 0;
+		tmpblock->link.prev_page = NULL;
 		tmpblock->link.prev_offset = 0;
 		put_ptr_atomic(tmpblock, KM_USER1);
 	}
@@ -284,7 +274,7 @@ static int grow_pool(struct xv_pool *pool, gfp_t flags)
 	if (unlikely(!page))
 		return -ENOMEM;
 
-	stat_inc(&pool->total_pages);
+	pool->total_pages++;
 
 	spin_lock(&pool->lock);
 	block = get_ptr_atomic(page, 0, KM_USER0);
@@ -361,8 +351,6 @@ int xv_malloc(struct xv_pool *pool, u32 size, struct page **page,
 
 	if (!*page) {
 		spin_unlock(&pool->lock);
-		if (flags & GFP_NOWAIT)
-			return -ENOMEM;
 		error = grow_pool(pool, flags);
 		if (unlikely(error))
 			return error;
@@ -472,7 +460,7 @@ void xv_free(struct xv_pool *pool, struct page *page, u32 offset)
 		spin_unlock(&pool->lock);
 
 		__free_page(page);
-		stat_dec(&pool->total_pages);
+		pool->total_pages--;
 		return;
 	}
 
diff --git a/drivers/staging/zram/zram.txt b/drivers/staging/zram/zram.txt
index 520edc1..5f75d29 100644
--- a/drivers/staging/zram/zram.txt
+++ b/drivers/staging/zram/zram.txt
@@ -5,33 +5,35 @@ Project home: http://compcache.googlecode.com/
 
 * Introduction
 
-The zram module creates RAM based block devices: /dev/ramX (X = 0, 1, ...).
-Pages written to these disks are compressed and stored in memory itself.
-These disks allow very fast I/O and compression provides good amounts of
-memory savings.
+The zram module creates RAM based block devices named /dev/zram<id>
+(<id> = 0, 1, ...). Pages written to these disks are compressed and stored
+in memory itself. These disks allow very fast I/O and compression provides
+good amounts of memory savings. Some of the usecases include /tmp storage,
+use as swap disks, various caches under /var and maybe many more :)
 
-See project home for use cases, performance numbers and a lot more.
-
-Individual zram devices are configured and initialized using zramconfig
-userspace utility as shown in examples below. See zramconfig man page for
-more details.
+Statistics for individual zram devices are exported through sysfs nodes at
+/sys/block/zram<id>/
 
 * Usage
 
 Following shows a typical sequence of steps for using zram.
 
-1) Load Modules:
+1) Load Module:
 	modprobe zram num_devices=4
-	This creates 4 (uninitialized) devices: /dev/zram{0,1,2,3}
+	This creates 4 devices: /dev/zram{0,1,2,3}
 	(num_devices parameter is optional. Default: 1)
 
-2) Initialize:
-	Use zramconfig utility to configure and initialize individual
-	zram devices. For example:
-	zramconfig /dev/zram0 --init # uses default value of disksize_kb
-	zramconfig /dev/zram1 --disksize_kb=102400 # 100MB /dev/zram1
+2) Set Disksize (Optional):
+	Set disk size by writing the value to sysfs node 'disksize'
+	(in bytes). If disksize is not given, default value of 25%
+	of RAM is used.
+
+	# Initialize /dev/zram0 with 50MB disksize
+	echo $((50*1024*1024)) > /sys/block/zram0/disksize
 
-	*See zramconfig man page for more details and examples*
+	NOTE: disksize cannot be changed if the disk contains any
+	data. So, for such a disk, you need to issue 'reset' (see below)
+	before you can change its disksize.
 
 3) Activate:
 	mkswap /dev/zram0
@@ -41,17 +43,29 @@ Following shows a typical sequence of steps for using zram.
 	mount /dev/zram1 /tmp
 
 4) Stats:
-	zramconfig /dev/zram0 --stats
-	zramconfig /dev/zram1 --stats
+	Per-device statistics are exported as various nodes under
+	/sys/block/zram<id>/
+		disksize
+		num_reads
+		num_writes
+		invalid_io
+		notify_free
+		discard
+		zero_pages
+		orig_data_size
+		compr_data_size
+		mem_used_total
 
 5) Deactivate:
 	swapoff /dev/zram0
 	umount /dev/zram1
 
 6) Reset:
-	zramconfig /dev/zram0 --reset
-	zramconfig /dev/zram1 --reset
-	(This frees memory allocated for the given device).
+	Write any positive value to 'reset' sysfs node
+	echo 1 > /sys/block/zram0/reset
+	echo 1 > /sys/block/zram1/reset
+
+	(This frees all the memory allocated for the given device).
 
 
 Please report any problems at:
diff --git a/drivers/staging/zram/zram_drv.c b/drivers/staging/zram/zram_drv.c
index 77d4d71..42aa271 100644
--- a/drivers/staging/zram/zram_drv.c
+++ b/drivers/staging/zram/zram_drv.c
@@ -9,7 +9,7 @@
  * Released under the terms of 3-clause BSD License
  * Released under the terms of GNU General Public License Version 2.0
  *
- * Project home: http://compcache.googlecode.com
+ * Project home: http://compcache.googlecode.com/
  */
 
 #define KMSG_COMPONENT "zram"
@@ -17,13 +17,14 @@
 
 #include <linux/module.h>
 #include <linux/kernel.h>
-#include <linux/bio.h>
 #include <linux/bitops.h>
 #include <linux/blkdev.h>
 #include <linux/buffer_head.h>
+#include <linux/cpu.h>
 #include <linux/device.h>
 #include <linux/genhd.h>
 #include <linux/highmem.h>
+#include <linux/notifier.h>
 #include <linux/slab.h>
 #include <linux/lzo.h>
 #include <linux/string.h>
@@ -31,29 +32,44 @@
 
 #include "zram_drv.h"
 
+static DEFINE_PER_CPU(unsigned char *, compress_buffer);
+static DEFINE_PER_CPU(unsigned char *, compress_workmem);
+
 /* Globals */
 static int zram_major;
-static struct zram *devices;
+struct zram *devices;
 
 /* Module params (documentation at end) */
-static unsigned int num_devices;
+unsigned int num_devices;
+
+/*
+ * We do not allocate any memory for zero-filled pages.
+ * Rather, we simply mark them in corresponding table
+ * entry by setting this bit.
+ */
+#define ZRAM_ZERO_PAGE_MARK_BIT		(1 << 0)
 
-static int zram_test_flag(struct zram *zram, u32 index,
-			enum zram_pageflags flag)
+static void zram_add_stat(struct zram *zram,
+			enum zram_stats_index idx, s64 val)
 {
-	return zram->table[index].flags & BIT(flag);
+	struct zram_stats_cpu *stats;
+
+	preempt_disable();
+	stats = __this_cpu_ptr(zram->stats);
+	u64_stats_update_begin(&stats->syncp);
+	stats->count[idx] += val;
+	u64_stats_update_end(&stats->syncp);
+	preempt_enable();
 }
 
-static void zram_set_flag(struct zram *zram, u32 index,
-			enum zram_pageflags flag)
+static void zram_inc_stat(struct zram *zram, enum zram_stats_index idx)
 {
-	zram->table[index].flags |= BIT(flag);
+	zram_add_stat(zram, idx, 1);
 }
 
-static void zram_clear_flag(struct zram *zram, u32 index,
-			enum zram_pageflags flag)
+static void zram_dec_stat(struct zram *zram, enum zram_stats_index idx)
 {
-	zram->table[index].flags &= ~BIT(flag);
+	zram_add_stat(zram, idx, -1);
 }
 
 static int page_zero_filled(void *ptr)
@@ -71,120 +87,100 @@ static int page_zero_filled(void *ptr)
 	return 1;
 }
 
-static void zram_set_disksize(struct zram *zram, size_t totalram_bytes)
+static int zram_is_zero_page(struct zram *zram, u32 index)
 {
-	if (!zram->disksize) {
-		pr_info(
-		"disk size not provided. You can use disksize_kb module "
-		"param to specify size.\nUsing default: (%u%% of RAM).\n",
-		default_disksize_perc_ram
-		);
-		zram->disksize = default_disksize_perc_ram *
-					(totalram_bytes / 100);
-	}
+	phys_addr_t addr = zram->table[index].addr;
 
-	if (zram->disksize > 2 * (totalram_bytes)) {
-		pr_info(
-		"There is little point creating a zram of greater than "
-		"twice the size of memory since we expect a 2:1 compression "
-		"ratio. Note that zram uses about 0.1%% of the size of "
-		"the disk when not in use so a huge zram is "
-		"wasteful.\n"
-		"\tMemory Size: %zu kB\n"
-		"\tSize you selected: %zu kB\n"
-		"Continuing anyway ...\n",
-		totalram_bytes >> 10, zram->disksize
-		);
-	}
+	return addr & ZRAM_ZERO_PAGE_MARK_BIT;
+}
 
-	zram->disksize &= PAGE_MASK;
+static void zram_set_zero_page(struct zram *zram, u32 index)
+{
+	zram->table[index].addr |= ZRAM_ZERO_PAGE_MARK_BIT;
 }
 
-static void zram_ioctl_get_stats(struct zram *zram,
-			struct zram_ioctl_stats *s)
+static void zram_clear_zero_page(struct zram *zram, u32 index)
 {
-	s->disksize = zram->disksize;
-
-#if defined(CONFIG_ZRAM_STATS)
-	{
-	struct zram_stats *rs = &zram->stats;
-	size_t succ_writes, mem_used;
-	unsigned int good_compress_perc = 0, no_compress_perc = 0;
-
-	mem_used = xv_get_total_size_bytes(zram->mem_pool)
-			+ (rs->pages_expand << PAGE_SHIFT);
-	succ_writes = zram_stat64_read(zram, &rs->num_writes) -
-			zram_stat64_read(zram, &rs->failed_writes);
-
-	if (succ_writes && rs->pages_stored) {
-		good_compress_perc = rs->good_compress * 100
-					/ rs->pages_stored;
-		no_compress_perc = rs->pages_expand * 100
-					/ rs->pages_stored;
-	}
+	zram->table[index].addr &= ~ZRAM_ZERO_PAGE_MARK_BIT;
+}
 
-	s->num_reads = zram_stat64_read(zram, &rs->num_reads);
-	s->num_writes = zram_stat64_read(zram, &rs->num_writes);
-	s->failed_reads = zram_stat64_read(zram, &rs->failed_reads);
-	s->failed_writes = zram_stat64_read(zram, &rs->failed_writes);
-	s->invalid_io = zram_stat64_read(zram, &rs->invalid_io);
-	s->notify_free = zram_stat64_read(zram, &rs->notify_free);
-	s->pages_zero = rs->pages_zero;
-
-	s->good_compress_pct = good_compress_perc;
-	s->pages_expand_pct = no_compress_perc;
-
-	s->pages_stored = rs->pages_stored;
-	s->pages_used = mem_used >> PAGE_SHIFT;
-	s->orig_data_size = rs->pages_stored << PAGE_SHIFT;
-	s->compr_data_size = rs->compr_size;
-	s->mem_used_total = mem_used;
+static void zram_find_obj(struct zram *zram, u32 index, struct page **page,
+			u32 *offset)
+{
+	phys_addr_t addr = zram->table[index].addr;
+
+	if (!addr) {
+		*page = NULL;
+		*offset = 0;
+		return;
 	}
-#endif /* CONFIG_ZRAM_STATS */
+
+	*page = pfn_to_page(addr >> PAGE_SHIFT);
+	*offset = addr & ~PAGE_MASK;
+}
+
+static void zram_insert_obj(struct zram *zram, u32 index, struct page *page,
+			u32 offset)
+{
+	phys_addr_t addr;
+
+	addr = page_to_pfn(page) << PAGE_SHIFT;
+	addr |= (offset & ~PAGE_MASK);
+
+	zram->table[index].addr = addr;
+}
+
+static u64 zram_default_disksize(void)
+{
+	u64 disksize;
+
+	disksize = default_disksize_perc_ram *
+			(totalram_pages / 100);
+	disksize = (disksize << PAGE_SHIFT) & PAGE_MASK;
+
+	return disksize;
 }
 
 static void zram_free_page(struct zram *zram, size_t index)
 {
-	u32 clen;
+	int zlen;
 	void *obj;
+	u32 offset;
+	struct page *page;
 
-	struct page *page = zram->table[index].page;
-	u32 offset = zram->table[index].offset;
-
-	if (unlikely(!page)) {
-		/*
-		 * No memory is allocated for zero filled pages.
-		 * Simply clear zero page flag.
-		 */
-		if (zram_test_flag(zram, index, ZRAM_ZERO)) {
-			zram_clear_flag(zram, index, ZRAM_ZERO);
-			zram_stat_dec(&zram->stats.pages_zero);
-		}
+	/*
+	 * No memory is allocated for zero filled pages.
+	 * Simply clear corresponding table entry.
+	 */
+	if (zram_is_zero_page(zram, index)) {
+		zram_clear_zero_page(zram, index);
+		zram_dec_stat(zram, ZRAM_STAT_PAGES_ZERO);
 		return;
 	}
 
-	if (unlikely(zram_test_flag(zram, index, ZRAM_UNCOMPRESSED))) {
-		clen = PAGE_SIZE;
+	zram_find_obj(zram, index, &page, &offset);
+	if (!page)
+		return;
+
+	/* Uncompressed pages cosume whole page, so offset is zero */
+	if (unlikely(!offset)) {
+		zlen = PAGE_SIZE;
 		__free_page(page);
-		zram_clear_flag(zram, index, ZRAM_UNCOMPRESSED);
-		zram_stat_dec(&zram->stats.pages_expand);
+		zram_dec_stat(zram, ZRAM_STAT_PAGES_EXPAND);
 		goto out;
 	}
 
 	obj = kmap_atomic(page, KM_USER0) + offset;
-	clen = xv_get_object_size(obj) - sizeof(struct zobj_header);
+	zlen = xv_get_object_size(obj);
 	kunmap_atomic(obj, KM_USER0);
 
 	xv_free(zram->mem_pool, page, offset);
-	if (clen <= PAGE_SIZE / 2)
-		zram_stat_dec(&zram->stats.good_compress);
 
 out:
-	zram->stats.compr_size -= clen;
-	zram_stat_dec(&zram->stats.pages_stored);
+	zram_add_stat(zram, ZRAM_STAT_COMPR_SIZE, -zlen);
+	zram_dec_stat(zram, ZRAM_STAT_PAGES_STORED);
 
-	zram->table[index].page = NULL;
-	zram->table[index].offset = 0;
+	zram->table[index].addr = 0;
 }
 
 static void handle_zero_page(struct page *page)
@@ -199,82 +195,90 @@ static void handle_zero_page(struct page *page)
 }
 
 static void handle_uncompressed_page(struct zram *zram,
-				struct page *page, u32 index)
+				struct page *bio_page, u32 index)
 {
-	unsigned char *user_mem, *cmem;
+	u32 zoffset;
+	struct page *zpage;
+	unsigned char *bio_mem, *zmem;
 
-	user_mem = kmap_atomic(page, KM_USER0);
-	cmem = kmap_atomic(zram->table[index].page, KM_USER1) +
-			zram->table[index].offset;
+	zram_find_obj(zram, index, &zpage, &zoffset);
+	BUG_ON(zoffset);
 
-	memcpy(user_mem, cmem, PAGE_SIZE);
-	kunmap_atomic(user_mem, KM_USER0);
-	kunmap_atomic(cmem, KM_USER1);
+	bio_mem = kmap_atomic(bio_page, KM_USER0);
+	zmem = kmap_atomic(zpage, KM_USER1);
 
-	flush_dcache_page(page);
+	memcpy(bio_mem, zmem, PAGE_SIZE);
+	kunmap_atomic(bio_mem, KM_USER0);
+	kunmap_atomic(zmem, KM_USER1);
+
+	flush_dcache_page(bio_page);
 }
 
 static int zram_read(struct zram *zram, struct bio *bio)
 {
-
 	int i;
 	u32 index;
 	struct bio_vec *bvec;
 
-	zram_stat64_inc(zram, &zram->stats.num_reads);
+	if (unlikely(!zram->init_done)) {
+		set_bit(BIO_UPTODATE, &bio->bi_flags);
+		bio_endio(bio, 0);
+		return 0;
+	}
 
+	zram_inc_stat(zram, ZRAM_STAT_NUM_READS);
 	index = bio->bi_sector >> SECTORS_PER_PAGE_SHIFT;
+
 	bio_for_each_segment(bvec, bio, i) {
 		int ret;
-		size_t clen;
-		struct page *page;
-		struct zobj_header *zheader;
-		unsigned char *user_mem, *cmem;
+		size_t zlen;
+		u32 zoffset;
+		struct page *bio_page, *zpage;
+		unsigned char *bio_mem, *zmem;
 
-		page = bvec->bv_page;
+		bio_page = bvec->bv_page;
 
-		if (zram_test_flag(zram, index, ZRAM_ZERO)) {
-			handle_zero_page(page);
+		if (zram_is_zero_page(zram, index)) {
+			handle_zero_page(bio_page);
 			continue;
 		}
 
+		zram_find_obj(zram, index, &zpage, &zoffset);
+
 		/* Requested page is not present in compressed area */
-		if (unlikely(!zram->table[index].page)) {
-			pr_debug("Read before write: sector=%lu, size=%u",
+		if (unlikely(!zpage)) {
+			pr_debug("Read before write on swap device: "
+				"sector=%lu, size=%u",
 				(ulong)(bio->bi_sector), bio->bi_size);
 			/* Do nothing */
 			continue;
 		}
 
 		/* Page is stored uncompressed since it's incompressible */
-		if (unlikely(zram_test_flag(zram, index, ZRAM_UNCOMPRESSED))) {
-			handle_uncompressed_page(zram, page, index);
+		if (unlikely(!zoffset)) {
+			handle_uncompressed_page(zram, bio_page, index);
 			continue;
 		}
 
-		user_mem = kmap_atomic(page, KM_USER0);
-		clen = PAGE_SIZE;
+		bio_mem = kmap_atomic(bio_page, KM_USER0);
+		zlen = PAGE_SIZE;
 
-		cmem = kmap_atomic(zram->table[index].page, KM_USER1) +
-				zram->table[index].offset;
+		zmem = kmap_atomic(zpage, KM_USER1) + zoffset;
 
-		ret = lzo1x_decompress_safe(
-			cmem + sizeof(*zheader),
-			xv_get_object_size(cmem) - sizeof(*zheader),
-			user_mem, &clen);
+		ret = lzo1x_decompress_safe(zmem, xv_get_object_size(zmem),
+					bio_mem, &zlen);
 
-		kunmap_atomic(user_mem, KM_USER0);
-		kunmap_atomic(cmem, KM_USER1);
+		kunmap_atomic(bio_mem, KM_USER0);
+		kunmap_atomic(zmem, KM_USER1);
 
-		/* Should NEVER happen. Return bio error if it does. */
+		/* This should NEVER happen - return bio error if it does! */
 		if (unlikely(ret != LZO_E_OK)) {
 			pr_err("Decompression failed! err=%d, page=%u\n",
 				ret, index);
-			zram_stat64_inc(zram, &zram->stats.failed_reads);
 			goto out;
 		}
 
-		flush_dcache_page(page);
+		flush_dcache_page(bio_page);
 		index++;
 	}
 
@@ -289,119 +293,103 @@ out:
 
 static int zram_write(struct zram *zram, struct bio *bio)
 {
-	int i;
+	int i, ret;
 	u32 index;
 	struct bio_vec *bvec;
 
-	zram_stat64_inc(zram, &zram->stats.num_writes);
+	if (unlikely(!zram->init_done)) {
+		ret = zram_init_device(zram);
+		if (ret)
+			goto out;
+	}
 
+	zram_inc_stat(zram, ZRAM_STAT_NUM_WRITES);
 	index = bio->bi_sector >> SECTORS_PER_PAGE_SHIFT;
 
 	bio_for_each_segment(bvec, bio, i) {
-		int ret;
-		u32 offset;
-		size_t clen;
-		struct zobj_header *zheader;
-		struct page *page, *page_store;
-		unsigned char *user_mem, *cmem, *src;
+		size_t zlen;
+		u32 zoffset;
+		struct page *bio_page, *zpage;
+		unsigned char *zbuffer, *zworkmem;
+		unsigned char *bio_mem, *zmem, *src;
 
-		page = bvec->bv_page;
-		src = zram->compress_buffer;
+		bio_page = bvec->bv_page;
 
 		/*
 		 * System overwrites unused sectors. Free memory associated
-		 * with this sector now.
+		 * with this sector now (if used).
 		 */
-		if (zram->table[index].page ||
-				zram_test_flag(zram, index, ZRAM_ZERO))
-			zram_free_page(zram, index);
-
-		mutex_lock(&zram->lock);
-
-		user_mem = kmap_atomic(page, KM_USER0);
-		if (page_zero_filled(user_mem)) {
-			kunmap_atomic(user_mem, KM_USER0);
-			mutex_unlock(&zram->lock);
-			zram_stat_inc(&zram->stats.pages_zero);
-			zram_set_flag(zram, index, ZRAM_ZERO);
+		zram_free_page(zram, index);
+
+		preempt_disable();
+		zbuffer = __get_cpu_var(compress_buffer);
+		zworkmem = __get_cpu_var(compress_workmem);
+		if (unlikely(!zbuffer || !zworkmem)) {
+			preempt_enable();
+			goto out;
+		}
+
+		src = zbuffer;
+		bio_mem = kmap_atomic(bio_page, KM_USER0);
+		if (page_zero_filled(bio_mem)) {
+			kunmap_atomic(bio_mem, KM_USER0);
+			preempt_enable();
+			zram_inc_stat(zram, ZRAM_STAT_PAGES_ZERO);
+			zram_set_zero_page(zram, index);
 			continue;
 		}
 
-		ret = lzo1x_1_compress(user_mem, PAGE_SIZE, src, &clen,
-					zram->compress_workmem);
+		ret = lzo1x_1_compress(bio_mem, PAGE_SIZE, src, &zlen,
+					zworkmem);
 
-		kunmap_atomic(user_mem, KM_USER0);
+		kunmap_atomic(bio_mem, KM_USER0);
 
 		if (unlikely(ret != LZO_E_OK)) {
-			mutex_unlock(&zram->lock);
+			preempt_enable();
 			pr_err("Compression failed! err=%d\n", ret);
-			zram_stat64_inc(zram, &zram->stats.failed_writes);
 			goto out;
 		}
 
-		/*
-		 * Page is incompressible. Store it as-is (uncompressed)
-		 * since we do not want to return too many disk write
-		 * errors which has side effect of hanging the system.
-		 */
-		if (unlikely(clen > max_zpage_size)) {
-			clen = PAGE_SIZE;
-			page_store = alloc_page(GFP_NOIO | __GFP_HIGHMEM);
-			if (unlikely(!page_store)) {
-				mutex_unlock(&zram->lock);
+		 /* Page is incompressible. Store it as-is (uncompressed) */
+		if (unlikely(zlen > max_zpage_size)) {
+			zlen = PAGE_SIZE;
+			zpage = alloc_page(GFP_NOWAIT | __GFP_HIGHMEM);
+			if (unlikely(!zpage)) {
+				preempt_enable();
 				pr_info("Error allocating memory for "
 					"incompressible page: %u\n", index);
-				zram_stat64_inc(zram,
-					&zram->stats.failed_writes);
 				goto out;
 			}
 
-			offset = 0;
-			zram_set_flag(zram, index, ZRAM_UNCOMPRESSED);
-			zram_stat_inc(&zram->stats.pages_expand);
-			zram->table[index].page = page_store;
-			src = kmap_atomic(page, KM_USER0);
+			zoffset = 0;
+			zram_inc_stat(zram, ZRAM_STAT_PAGES_EXPAND);
+			src = kmap_atomic(zpage, KM_USER0);
 			goto memstore;
 		}
 
-		if (xv_malloc(zram->mem_pool, clen + sizeof(*zheader),
-				&zram->table[index].page, &offset,
-				GFP_NOIO | __GFP_HIGHMEM)) {
-			mutex_unlock(&zram->lock);
+		if (xv_malloc(zram->mem_pool, zlen, &zpage, &zoffset,
+				GFP_NOWAIT | __GFP_HIGHMEM)) {
+			preempt_enable();
 			pr_info("Error allocating memory for compressed "
-				"page: %u, size=%zu\n", index, clen);
-			zram_stat64_inc(zram, &zram->stats.failed_writes);
+				"page: %u, size=%zu\n", index, zlen);
 			goto out;
 		}
 
 memstore:
-		zram->table[index].offset = offset;
-
-		cmem = kmap_atomic(zram->table[index].page, KM_USER1) +
-				zram->table[index].offset;
-
-#if 0
-		/* Back-reference needed for memory defragmentation */
-		if (!zram_test_flag(zram, index, ZRAM_UNCOMPRESSED)) {
-			zheader = (struct zobj_header *)cmem;
-			zheader->table_idx = index;
-			cmem += sizeof(*zheader);
-		}
-#endif
+		zmem = kmap_atomic(zpage, KM_USER1) + zoffset;
 
-		memcpy(cmem, src, clen);
+		memcpy(zmem, src, zlen);
+		kunmap_atomic(zmem, KM_USER1);
+		preempt_enable();
 
-		kunmap_atomic(cmem, KM_USER1);
-		if (unlikely(zram_test_flag(zram, index, ZRAM_UNCOMPRESSED)))
+		if (unlikely(!zoffset))
 			kunmap_atomic(src, KM_USER0);
 
 		/* Update stats */
-		zram->stats.compr_size += clen;
-		zram_stat_inc(&zram->stats.pages_stored);
-		if (clen <= PAGE_SIZE / 2)
-			zram_stat_inc(&zram->stats.good_compress);
+		zram_add_stat(zram, ZRAM_STAT_COMPR_SIZE, zlen);
+		zram_inc_stat(zram, ZRAM_STAT_PAGES_STORED);
 
-		mutex_unlock(&zram->lock);
+		zram_insert_obj(zram, index, zpage, zoffset);
 		index++;
 	}
 
@@ -414,6 +402,20 @@ out:
 	return 0;
 }
 
+static void zram_discard(struct zram *zram, struct bio *bio)
+{
+	size_t bytes = bio->bi_size;
+	sector_t sector = bio->bi_sector;
+
+	while (bytes >= PAGE_SIZE) {
+		zram_free_page(zram, sector >> SECTORS_PER_PAGE_SHIFT);
+		sector += PAGE_SIZE >> SECTOR_SHIFT;
+		bytes -= PAGE_SIZE;
+	}
+
+	bio_endio(bio, 0);
+}
+
 /*
  * Check if request is within bounds and page aligned.
  */
@@ -439,14 +441,15 @@ static int zram_make_request(struct request_queue *queue, struct bio *bio)
 	int ret = 0;
 	struct zram *zram = queue->queuedata;
 
-	if (unlikely(!zram->init_done)) {
+	if (unlikely(!valid_io_request(zram, bio))) {
+		zram_inc_stat(zram, ZRAM_STAT_INVALID_IO);
 		bio_io_error(bio);
 		return 0;
 	}
 
-	if (!valid_io_request(zram, bio)) {
-		zram_stat64_inc(zram, &zram->stats.invalid_io);
-		bio_io_error(bio);
+	if (unlikely(bio_rw_flagged(bio, BIO_RW_DISCARD))) {
+		zram_inc_stat(zram, ZRAM_STAT_DISCARD);
+		zram_discard(zram, bio);
 		return 0;
 	}
 
@@ -463,36 +466,16 @@ static int zram_make_request(struct request_queue *queue, struct bio *bio)
 	return ret;
 }
 
-static void reset_device(struct zram *zram)
+void zram_reset_device(struct zram *zram)
 {
 	size_t index;
 
-	/* Do not accept any new I/O request */
+	mutex_lock(&zram->init_lock);
 	zram->init_done = 0;
 
-	/* Free various per-device buffers */
-	kfree(zram->compress_workmem);
-	free_pages((unsigned long)zram->compress_buffer, 1);
-
-	zram->compress_workmem = NULL;
-	zram->compress_buffer = NULL;
-
 	/* Free all pages that are still in this zram device */
-	for (index = 0; index < zram->disksize >> PAGE_SHIFT; index++) {
-		struct page *page;
-		u16 offset;
-
-		page = zram->table[index].page;
-		offset = zram->table[index].offset;
-
-		if (!page)
-			continue;
-
-		if (unlikely(zram_test_flag(zram, index, ZRAM_UNCOMPRESSED)))
-			__free_page(page);
-		else
-			xv_free(zram->mem_pool, page, offset);
-	}
+	for (index = 0; index < zram->disksize >> PAGE_SHIFT; index++)
+		zram_free_page(zram, index);
 
 	vfree(zram->table);
 	zram->table = NULL;
@@ -503,34 +486,24 @@ static void reset_device(struct zram *zram)
 	/* Reset stats */
 	memset(&zram->stats, 0, sizeof(zram->stats));
 
-	zram->disksize = 0;
+	zram->disksize = zram_default_disksize();
+	mutex_unlock(&zram->init_lock);
 }
 
-static int zram_ioctl_init_device(struct zram *zram)
+int zram_init_device(struct zram *zram)
 {
 	int ret;
 	size_t num_pages;
 
-	if (zram->init_done) {
-		pr_info("Device already initialized!\n");
-		return -EBUSY;
-	}
-
-	zram_set_disksize(zram, totalram_pages << PAGE_SHIFT);
+	mutex_lock(&zram->init_lock);
 
-	zram->compress_workmem = kzalloc(LZO1X_MEM_COMPRESS, GFP_KERNEL);
-	if (!zram->compress_workmem) {
-		pr_err("Error allocating compressor working memory!\n");
-		ret = -ENOMEM;
-		goto fail;
+	if (zram->init_done) {
+		mutex_unlock(&zram->init_lock);
+		return 0;
 	}
 
-	zram->compress_buffer = (void *)__get_free_pages(__GFP_ZERO, 1);
-	if (!zram->compress_buffer) {
-		pr_err("Error allocating compressor buffer space\n");
-		ret = -ENOMEM;
-		goto fail;
-	}
+	if (!zram->disksize)
+		zram->disksize = zram_default_disksize();
 
 	num_pages = zram->disksize >> PAGE_SHIFT;
 	zram->table = vmalloc(num_pages * sizeof(*zram->table));
@@ -548,6 +521,13 @@ static int zram_ioctl_init_device(struct zram *zram)
 	/* zram devices sort of resembles non-rotational disks */
 	queue_flag_set_unlocked(QUEUE_FLAG_NONROT, zram->disk->queue);
 
+	zram->stats = alloc_percpu(struct zram_stats_cpu);
+	if (!zram->stats) {
+		pr_err("Error allocating percpu stats\n");
+		ret = -ENOMEM;
+		goto fail;
+	}
+
 	zram->mem_pool = xv_create_pool();
 	if (!zram->mem_pool) {
 		pr_err("Error creating memory pool\n");
@@ -556,107 +536,30 @@ static int zram_ioctl_init_device(struct zram *zram)
 	}
 
 	zram->init_done = 1;
+	mutex_unlock(&zram->init_lock);
 
 	pr_debug("Initialization done!\n");
 	return 0;
 
 fail:
-	reset_device(zram);
+	mutex_unlock(&zram->init_lock);
+	zram_reset_device(zram);
 
 	pr_err("Initialization failed: err=%d\n", ret);
 	return ret;
 }
 
-static int zram_ioctl_reset_device(struct zram *zram)
-{
-	if (zram->init_done)
-		reset_device(zram);
-
-	return 0;
-}
-
-static int zram_ioctl(struct block_device *bdev, fmode_t mode,
-			unsigned int cmd, unsigned long arg)
-{
-	int ret = 0;
-	size_t disksize_kb;
-
-	struct zram *zram = bdev->bd_disk->private_data;
-
-	switch (cmd) {
-	case ZRAMIO_SET_DISKSIZE_KB:
-		if (zram->init_done) {
-			ret = -EBUSY;
-			goto out;
-		}
-		if (copy_from_user(&disksize_kb, (void *)arg,
-						_IOC_SIZE(cmd))) {
-			ret = -EFAULT;
-			goto out;
-		}
-		zram->disksize = disksize_kb << 10;
-		pr_info("Disk size set to %zu kB\n", disksize_kb);
-		break;
-
-	case ZRAMIO_GET_STATS:
-	{
-		struct zram_ioctl_stats *stats;
-		if (!zram->init_done) {
-			ret = -ENOTTY;
-			goto out;
-		}
-		stats = kzalloc(sizeof(*stats), GFP_KERNEL);
-		if (!stats) {
-			ret = -ENOMEM;
-			goto out;
-		}
-		zram_ioctl_get_stats(zram, stats);
-		if (copy_to_user((void *)arg, stats, sizeof(*stats))) {
-			kfree(stats);
-			ret = -EFAULT;
-			goto out;
-		}
-		kfree(stats);
-		break;
-	}
-	case ZRAMIO_INIT:
-		ret = zram_ioctl_init_device(zram);
-		break;
-
-	case ZRAMIO_RESET:
-		/* Do not reset an active device! */
-		if (bdev->bd_holders) {
-			ret = -EBUSY;
-			goto out;
-		}
-
-		/* Make sure all pending I/O is finished */
-		if (bdev)
-			fsync_bdev(bdev);
-
-		ret = zram_ioctl_reset_device(zram);
-		break;
-
-	default:
-		pr_info("Invalid ioctl %u\n", cmd);
-		ret = -ENOTTY;
-	}
-
-out:
-	return ret;
-}
-
-void zram_slot_free_notify(struct block_device *bdev, unsigned long index)
+static void zram_slot_free_notify(struct block_device *bdev,
+				unsigned long index)
 {
 	struct zram *zram;
 
 	zram = bdev->bd_disk->private_data;
 	zram_free_page(zram, index);
-	zram_stat64_inc(zram, &zram->stats.notify_free);
+	zram_inc_stat(zram, ZRAM_STAT_NOTIFY_FREE);
 }
 
 static const struct block_device_operations zram_devops = {
-	.ioctl = zram_ioctl,
 	.swap_slot_free_notify = zram_slot_free_notify,
 	.owner = THIS_MODULE
 };
@@ -665,8 +568,7 @@ static int create_device(struct zram *zram, int device_id)
 {
 	int ret = 0;
 
-	mutex_init(&zram->lock);
-	spin_lock_init(&zram->stat64_lock);
+	mutex_init(&zram->init_lock);
 
 	zram->queue = blk_alloc_queue(GFP_KERNEL);
 	if (!zram->queue) {
@@ -696,8 +598,9 @@ static int create_device(struct zram *zram, int device_id)
 	zram->disk->private_data = zram;
 	snprintf(zram->disk->disk_name, 16, "zram%d", device_id);
 
-	/* Actual capacity set using ZRAMIO_SET_DISKSIZE_KB ioctl */
-	set_capacity(zram->disk, 0);
+	/* Custom size can be set using syfs (/sys/block/zram<id>/disksize) */
+	zram->disksize = zram_default_disksize();
+	set_capacity(zram->disk, zram->disksize >> SECTOR_SHIFT);
 
 	/*
 	 * To ensure that we always get PAGE_SIZE aligned
@@ -708,8 +611,22 @@ static int create_device(struct zram *zram, int device_id)
 	blk_queue_io_min(zram->disk->queue, PAGE_SIZE);
 	blk_queue_io_opt(zram->disk->queue, PAGE_SIZE);
 
+	zram->disk->queue->limits.discard_granularity = PAGE_SIZE;
+	zram->disk->queue->limits.max_discard_sectors = UINT_MAX;
+	zram->disk->queue->limits.discard_zeroes_data = 1;
+	queue_flag_set_unlocked(QUEUE_FLAG_DISCARD, zram->queue);
+
 	add_disk(zram->disk);
 
+#ifdef CONFIG_SYSFS
+	ret = sysfs_create_group(&disk_to_dev(zram->disk)->kobj,
+				&zram_disk_attr_group);
+	if (ret < 0) {
+		pr_warning("Error creating sysfs group");
+		goto out;
+	}
+#endif
+
 	zram->init_done = 0;
 
 out:
@@ -718,6 +635,11 @@ out:
 
 static void destroy_device(struct zram *zram)
 {
+#ifdef CONFIG_SYSFS
+	sysfs_remove_group(&disk_to_dev(zram->disk)->kobj,
+			&zram_disk_attr_group);
+#endif
+
 	if (zram->disk) {
 		del_gendisk(zram->disk);
 		put_disk(zram->disk);
@@ -727,9 +649,46 @@ static void destroy_device(struct zram *zram)
 		blk_cleanup_queue(zram->queue);
 }
 
+/*
+ * Callback for CPU hotplug events. Allocates percpu compression buffers.
+ */
+static int zram_cpu_notify(struct notifier_block *nb, unsigned long action,
+			void *pcpu)
+{
+	int cpu = (long)pcpu;
+
+	switch (action) {
+	case CPU_UP_PREPARE:
+		per_cpu(compress_buffer, cpu) = (void *)__get_free_pages(
+					GFP_KERNEL | __GFP_ZERO, 1);
+		per_cpu(compress_workmem, cpu) = kzalloc(
+					LZO1X_MEM_COMPRESS, GFP_KERNEL);
+
+		break;
+	case CPU_DEAD:
+	case CPU_UP_CANCELED:
+		free_pages((unsigned long)(per_cpu(compress_buffer, cpu)), 1);
+		per_cpu(compress_buffer, cpu) = NULL;
+
+		kfree(per_cpu(compress_buffer, cpu));
+		per_cpu(compress_buffer, cpu) = NULL;
+
+		break;
+	default:
+		break;
+	}
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block zram_cpu_nb = {
+	.notifier_call = zram_cpu_notify
+};
+
 static int __init zram_init(void)
 {
 	int ret, dev_id;
+	unsigned int cpu;
 
 	if (num_devices > max_num_devices) {
 		pr_warning("Invalid value for num_devices: %u\n",
@@ -738,6 +697,20 @@ static int __init zram_init(void)
 		goto out;
 	}
 
+	ret = register_cpu_notifier(&zram_cpu_nb);
+	if (ret)
+		goto out;
+
+	for_each_online_cpu(cpu) {
+		void *pcpu = (void *)(long)cpu;
+		zram_cpu_notify(&zram_cpu_nb, CPU_UP_PREPARE, pcpu);
+		if (!per_cpu(compress_buffer, cpu) ||
+					!per_cpu(compress_workmem, cpu)) {
+			ret = -ENOMEM;
+			goto out;
+		}
+	}
+
 	zram_major = register_blkdev(0, "zram");
 	if (zram_major <= 0) {
 		pr_warning("Unable to get major number\n");
@@ -751,7 +724,7 @@ static int __init zram_init(void)
 	}
 
 	/* Allocate the device array and initialize each one */
-	pr_info("Creating %u devices ...\n", num_devices);
+	pr_debug("Creating %u devices ...\n", num_devices);
 	devices = kzalloc(num_devices * sizeof(struct zram), GFP_KERNEL);
 	if (!devices) {
 		ret = -ENOMEM;
@@ -772,12 +745,18 @@ free_devices:
 unregister:
 	unregister_blkdev(zram_major, "zram");
 out:
+	for_each_online_cpu(cpu) {
+		void *pcpu = (void *)(long)cpu;
+		zram_cpu_notify(&zram_cpu_nb, CPU_UP_CANCELED, pcpu);
+	}
+
 	return ret;
 }
 
 static void __exit zram_exit(void)
 {
 	int i;
+	unsigned int cpu;
 	struct zram *zram;
 
 	for (i = 0; i < num_devices; i++) {
@@ -785,11 +764,18 @@ static void __exit zram_exit(void)
 
 		destroy_device(zram);
 		if (zram->init_done)
-			reset_device(zram);
+			zram_reset_device(zram);
 	}
 
 	unregister_blkdev(zram_major, "zram");
 
+	for_each_online_cpu(cpu) {
+		void *pcpu = (void *)(long)cpu;
+		zram_cpu_notify(&zram_cpu_nb, CPU_UP_CANCELED, pcpu);
+	}
+
+	unregister_cpu_notifier(&zram_cpu_nb);
+
 	kfree(devices);
 	pr_debug("Cleanup done!\n");
 }
diff --git a/drivers/staging/zram/zram_drv.h b/drivers/staging/zram/zram_drv.h
index 945f974..2cf36db 100644
--- a/drivers/staging/zram/zram_drv.h
+++ b/drivers/staging/zram/zram_drv.h
@@ -9,16 +9,15 @@
  * Released under the terms of 3-clause BSD License
  * Released under the terms of GNU General Public License Version 2.0
  *
- * Project home: http://compcache.googlecode.com
+ * Project home: http://compcache.googlecode.com/
  */
 
 #ifndef _ZRAM_DRV_H_
 #define _ZRAM_DRV_H_
 
-#include <linux/spinlock.h>
 #include <linux/mutex.h>
+#include <linux/u64_stats_sync.h>
 
-#include "zram_ioctl.h"
 #include "xvmalloc.h"
 
 /*
@@ -27,18 +26,6 @@
  */
 static const unsigned max_num_devices = 32;
 
-/*
- * Stored at beginning of each compressed object.
- *
- * It stores back-reference to table entry which points to this
- * object. This is required to support memory defragmentation.
- */
-struct zobj_header {
-#if 0
-	u32 table_idx;
-#endif
-};
-
 /*-- Configurable parameters */
 
 /* Default zram disk size: 25% of total RAM */
@@ -48,11 +35,10 @@ static const unsigned default_disksize_perc_ram = 25;
  * Pages that compress to size greater than this are stored
  * uncompressed in memory.
  */
-static const unsigned max_zpage_size = PAGE_SIZE / 4 * 3;
+static const unsigned max_zpage_size = PAGE_SIZE / 8 * 7;
 
 /*
- * NOTE: max_zpage_size must be less than or equal to:
- *   XV_MAX_ALLOC_SIZE - sizeof(struct zobj_header)
+ * NOTE: max_zpage_size must be less than or equal to XV_MAX_ALLOC_SIZE
  * otherwise, xv_malloc() would always return failure.
  */
 
@@ -63,102 +49,54 @@ static const unsigned max_zpage_size = PAGE_SIZE / 4 * 3;
 #define SECTORS_PER_PAGE_SHIFT	(PAGE_SHIFT - SECTOR_SHIFT)
 #define SECTORS_PER_PAGE	(1 << SECTORS_PER_PAGE_SHIFT)
 
-/* Flags for zram pages (table[page_no].flags) */
-enum zram_pageflags {
-	/* Page is stored uncompressed */
-	ZRAM_UNCOMPRESSED,
-
-	/* Page consists entirely of zeros */
-	ZRAM_ZERO,
-
-	__NR_ZRAM_PAGEFLAGS,
+/*
+ * Maintains swap slot to compressed object mapping.
+ */
+struct table {
+	phys_addr_t addr;	/* location of [compressed] object */
 };
 
-/*-- Data structures */
+enum zram_stats_index {
+	ZRAM_STAT_COMPR_SIZE,	/* compressed size of pages stored */
+	ZRAM_STAT_NUM_READS,	/* failed + successful */
+	ZRAM_STAT_NUM_WRITES,	/* --do-- */
+	ZRAM_STAT_INVALID_IO,	/* non-page-aligned I/O requests */
+	ZRAM_STAT_NOTIFY_FREE,	/* no. of swap slot free notifications */
+	ZRAM_STAT_DISCARD,	/* no. of block discard requests */
+	ZRAM_STAT_PAGES_ZERO,	/* no. of zero filled pages */
+	ZRAM_STAT_PAGES_STORED,	/* no. of pages currently stored */
+	ZRAM_STAT_PAGES_EXPAND,	/* no. of incompressible pages */
+	ZRAM_STAT_NSTATS,
+};
 
-/* Allocated for each disk page */
-struct table {
-	struct page *page;
-	u16 offset;
-	u8 count;	/* object ref count (not yet used) */
-	u8 flags;
-} __attribute__((aligned(4)));
-
-struct zram_stats {
-	/* basic stats */
-	size_t compr_size;	/* compressed size of pages stored -
-				 * needed to enforce memlimit */
-	/* more stats */
-#if defined(CONFIG_ZRAM_STATS)
-	u64 num_reads;		/* failed + successful */
-	u64 num_writes;		/* --do-- */
-	u64 failed_reads;	/* should NEVER! happen */
-	u64 failed_writes;	/* can happen when memory is too low */
-	u64 invalid_io;		/* non-page-aligned I/O requests */
-	u64 notify_free;	/* no. of swap slot free notifications */
-	u32 pages_zero;		/* no. of zero filled pages */
-	u32 pages_stored;	/* no. of pages currently stored */
-	u32 good_compress;	/* % of pages with compression ratio<=50% */
-	u32 pages_expand;	/* % of incompressible pages */
-#endif
+struct zram_stats_cpu {
+	s64 count[ZRAM_STAT_NSTATS];
+	struct u64_stats_sync syncp;
 };
 
 struct zram {
 	struct xv_pool *mem_pool;
-	void *compress_workmem;
-	void *compress_buffer;
 	struct table *table;
-	spinlock_t stat64_lock;	/* protect 64-bit stats */
-	struct mutex lock;	/* protect compression buffers against
-				 * concurrent writes */
 	struct request_queue *queue;
 	struct gendisk *disk;
-	int init_done;
+	unsigned int init_done;
+	/* Prevent concurrent execution of device init and reset */
+	struct mutex init_lock;
 	/*
 	 * This is the limit on amount of *uncompressed* worth of data
-	 * we can store in a disk.
+	 * we can store in a disk (in bytes).
 	 */
-	size_t disksize;	/* bytes */
-
-	struct zram_stats stats;
+	u64 disksize;
+	struct zram_stats_cpu *stats;	/* percpu stats */
 };
 
-/*-- */
-
-/* Debugging and Stats */
-#if defined(CONFIG_ZRAM_STATS)
-static void zram_stat_inc(u32 *v)
-{
-	*v = *v + 1;
-}
-
-static void zram_stat_dec(u32 *v)
-{
-	*v = *v - 1;
-}
-
-static void zram_stat64_inc(struct zram *zram, u64 *v)
-{
-	spin_lock(&zram->stat64_lock);
-	*v = *v + 1;
-	spin_unlock(&zram->stat64_lock);
-}
-
-static u64 zram_stat64_read(struct zram *zram, u64 *v)
-{
-	u64 val;
-
-	spin_lock(&zram->stat64_lock);
-	val = *v;
-	spin_unlock(&zram->stat64_lock);
-
-	return val;
-}
-#else
-#define zram_stat_inc(v)
-#define zram_stat_dec(v)
-#define zram_stat64_inc(r, v)
-#define zram_stat64_read(r, v)
-#endif /* CONFIG_ZRAM_STATS */
+extern struct zram *devices;
+extern unsigned int num_devices;
+#ifdef CONFIG_SYSFS
+extern struct attribute_group zram_disk_attr_group;
+#endif
+
+extern int zram_init_device(struct zram *zram);
+extern void zram_reset_device(struct zram *zram);
 
 #endif
diff --git a/drivers/staging/zram/zram_ioctl.h b/drivers/staging/zram/zram_ioctl.h
deleted file mode 100644
index 5c415fa..0000000
--- a/drivers/staging/zram/zram_ioctl.h
+++ /dev/null
@@ -1,41 +0,0 @@
-/*
- * Compressed RAM block device
- *
- * Copyright (C) 2008, 2009, 2010  Nitin Gupta
- *
- * This code is released using a dual license strategy: BSD/GPL
- * You can choose the licence that better fits your requirements.
- *
- * Released under the terms of 3-clause BSD License
- * Released under the terms of GNU General Public License Version 2.0
- *
- * Project home: http://compcache.googlecode.com
- */
-
-#ifndef _ZRAM_IOCTL_H_
-#define _ZRAM_IOCTL_H_
-
-struct zram_ioctl_stats {
-	u64 disksize;		/* disksize in bytes (user specifies in KB) */
-	u64 num_reads;		/* failed + successful */
-	u64 num_writes;		/* --do-- */
-	u64 failed_reads;	/* should NEVER! happen */
-	u64 failed_writes;	/* can happen when memory is too low */
-	u64 invalid_io;		/* non-page-aligned I/O requests */
-	u64 notify_free;	/* no. of swap slot free notifications */
-	u32 pages_zero;		/* no. of zero filled pages */
-	u32 good_compress_pct;	/* no. of pages with compression ratio<=50% */
-	u32 pages_expand_pct;	/* no. of incompressible pages */
-	u32 pages_stored;
-	u32 pages_used;
-	u64 orig_data_size;
-	u64 compr_data_size;
-	u64 mem_used_total;
-} __attribute__ ((packed, aligned(4)));
-
-#define ZRAMIO_SET_DISKSIZE_KB	_IOW('z', 0, size_t)
-#define ZRAMIO_GET_STATS	_IOR('z', 1, struct zram_ioctl_stats)
-#define ZRAMIO_INIT		_IO('z', 2)
-#define ZRAMIO_RESET		_IO('z', 3)
-
-#endif
diff --git a/drivers/staging/zram/zram_sysfs.c b/drivers/staging/zram/zram_sysfs.c
new file mode 100644
index 0000000..74971c0
--- /dev/null
+++ b/drivers/staging/zram/zram_sysfs.c
@@ -0,0 +1,253 @@
+/*
+ * Compressed RAM block device
+ *
+ * Copyright (C) 2008, 2009, 2010  Nitin Gupta
+ *
+ * This code is released using a dual license strategy: BSD/GPL
+ * You can choose the licence that better fits your requirements.
+ *
+ * Released under the terms of 3-clause BSD License
+ * Released under the terms of GNU General Public License Version 2.0
+ *
+ * Project home: http://compcache.googlecode.com/
+ */
+
+#include <linux/device.h>
+#include <linux/genhd.h>
+
+#include "zram_drv.h"
+
+#ifdef CONFIG_SYSFS
+
+/*
+ * Individual percpu values can go negative but the sum across all CPUs
+ * must always be positive (we store various counts). So, return sum as
+ * unsigned value.
+ */
+static u64 zram_get_stat(struct zram *zram, enum zram_stats_index idx)
+{
+	int cpu;
+	s64 val = 0;
+
+	for_each_possible_cpu(cpu) {
+		s64 temp;
+		unsigned int start;
+		struct zram_stats_cpu *stats;
+
+		stats = per_cpu_ptr(zram->stats, cpu);
+		do {
+			start = u64_stats_fetch_begin(&stats->syncp);
+			temp = stats->count[idx];
+		} while (u64_stats_fetch_retry(&stats->syncp, start));
+		val += temp;
+	}
+
+	WARN_ON(val < 0);
+	return val;
+}
+
+static struct zram *dev_to_zram(struct device *dev)
+{
+	int i;
+	struct zram *zram = NULL;
+
+	for (i = 0; i < num_devices; i++) {
+		zram = &devices[i];
+		if (disk_to_dev(zram->disk) == dev)
+			break;
+	}
+
+	return zram;
+}
+
+static ssize_t disksize_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct zram *zram = dev_to_zram(dev);
+
+	return sprintf(buf, "%llu\n", zram->disksize);
+}
+
+static ssize_t disksize_store(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t len)
+{
+	int ret;
+	struct zram *zram = dev_to_zram(dev);
+
+	if (zram->init_done) {
+		pr_info("Cannot change disksize for initialized device\n");
+		return -EBUSY;
+	}
+
+	ret = strict_strtoull(buf, 10, &zram->disksize);
+	if (ret)
+		return ret;
+
+	zram->disksize &= PAGE_MASK;
+	set_capacity(zram->disk, zram->disksize >> SECTOR_SHIFT);
+
+	return len;
+}
+
+static ssize_t initstate_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct zram *zram = dev_to_zram(dev);
+
+	return sprintf(buf, "%u\n", zram->init_done);
+}
+
+static ssize_t reset_store(struct device *dev,
+		struct device_attribute *attr, const char *buf, size_t len)
+{
+	int ret;
+	unsigned long do_reset;
+	struct zram *zram;
+	struct block_device *bdev;
+
+	zram = dev_to_zram(dev);
+	bdev = bdget_disk(zram->disk, 0);
+
+	/* Do not reset an active device! */
+	if (bdev->bd_holders)
+		return -EBUSY;
+
+	ret = strict_strtoul(buf, 10, &do_reset);
+	if (ret)
+		return ret;
+
+	if (!do_reset)
+		return -EINVAL;
+
+	/* Make sure all pending I/O is finished */
+	if (bdev)
+		fsync_bdev(bdev);
+
+	if (zram->init_done)
+		zram_reset_device(zram);
+
+	return len;
+}
+
+static ssize_t num_reads_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct zram *zram = dev_to_zram(dev);
+
+	return sprintf(buf, "%llu\n",
+		zram_get_stat(zram, ZRAM_STAT_NUM_READS));
+}
+
+static ssize_t num_writes_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct zram *zram = dev_to_zram(dev);
+
+	return sprintf(buf, "%llu\n",
+		zram_get_stat(zram, ZRAM_STAT_NUM_WRITES));
+}
+
+static ssize_t invalid_io_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct zram *zram = dev_to_zram(dev);
+
+	return sprintf(buf, "%llu\n",
+		zram_get_stat(zram, ZRAM_STAT_INVALID_IO));
+}
+
+static ssize_t notify_free_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct zram *zram = dev_to_zram(dev);
+
+	return sprintf(buf, "%llu\n",
+		zram_get_stat(zram, ZRAM_STAT_NOTIFY_FREE));
+}
+
+static ssize_t discard_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct zram *zram = dev_to_zram(dev);
+
+	return sprintf(buf, "%llu\n",
+		zram_get_stat(zram, ZRAM_STAT_DISCARD));
+}
+
+static ssize_t zero_pages_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct zram *zram = dev_to_zram(dev);
+
+	return sprintf(buf, "%llu\n",
+		zram_get_stat(zram, ZRAM_STAT_PAGES_ZERO));
+}
+
+static ssize_t orig_data_size_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct zram *zram = dev_to_zram(dev);
+
+	return sprintf(buf, "%llu\n",
+		zram_get_stat(zram, ZRAM_STAT_PAGES_STORED) << PAGE_SHIFT);
+}
+
+static ssize_t compr_data_size_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	struct zram *zram = dev_to_zram(dev);
+
+	return sprintf(buf, "%llu\n",
+		zram_get_stat(zram, ZRAM_STAT_COMPR_SIZE));
+}
+
+static ssize_t mem_used_total_show(struct device *dev,
+		struct device_attribute *attr, char *buf)
+{
+	u64 val = 0;
+	struct zram *zram = dev_to_zram(dev);
+
+	if (zram->init_done) {
+		val = xv_get_total_size_bytes(zram->mem_pool) +
+			(zram_get_stat(zram, ZRAM_STAT_PAGES_EXPAND)
+				<< PAGE_SHIFT);
+	}
+
+	return sprintf(buf, "%llu\n", val);
+}
+
+static DEVICE_ATTR(disksize, S_IRUGO | S_IWUGO,
+		disksize_show, disksize_store);
+static DEVICE_ATTR(initstate, S_IRUGO, initstate_show, NULL);
+static DEVICE_ATTR(reset, S_IWUGO, NULL, reset_store);
+static DEVICE_ATTR(num_reads, S_IRUGO, num_reads_show, NULL);
+static DEVICE_ATTR(num_writes, S_IRUGO, num_writes_show, NULL);
+static DEVICE_ATTR(invalid_io, S_IRUGO, invalid_io_show, NULL);
+static DEVICE_ATTR(notify_free, S_IRUGO, notify_free_show, NULL);
+static DEVICE_ATTR(discard, S_IRUGO, discard_show, NULL);
+static DEVICE_ATTR(zero_pages, S_IRUGO, zero_pages_show, NULL);
+static DEVICE_ATTR(orig_data_size, S_IRUGO, orig_data_size_show, NULL);
+static DEVICE_ATTR(compr_data_size, S_IRUGO, compr_data_size_show, NULL);
+static DEVICE_ATTR(mem_used_total, S_IRUGO, mem_used_total_show, NULL);
+
+static struct attribute *zram_disk_attrs[] = {
+	&dev_attr_disksize.attr,
+	&dev_attr_initstate.attr,
+	&dev_attr_reset.attr,
+	&dev_attr_num_reads.attr,
+	&dev_attr_num_writes.attr,
+	&dev_attr_invalid_io.attr,
+	&dev_attr_notify_free.attr,
+	&dev_attr_discard.attr,
+	&dev_attr_zero_pages.attr,
+	&dev_attr_orig_data_size.attr,
+	&dev_attr_compr_data_size.attr,
+	&dev_attr_mem_used_total.attr,
+	NULL,
+};
+
+struct attribute_group zram_disk_attr_group = {
+	.attrs = zram_disk_attrs,
+};
+
+#endif	/* CONFIG_SYSFS */
